import streamlit as st
from utils.github_client import GitHubClient
from utils.chunking import Chunker
from utils.embeddings import Embedder
from utils.embeddings import PineconeVectorStore
from agents.rag import RAGAgent
from langchain_community.llms import Ollama
from agents.orchestrator import OrchestratorAgent
from agents.github_agent import GitHubAgent, GitHubTool
from utils.query_analysis import QueryAnalyzer

def streamlit_logger(msg):
    st.info(msg)

def init_query_analyzer():
    """Inicializa el analizador de consultas"""
    if 'query_analyzer' not in st.session_state:
        llm = Ollama(model="llama3.2:1b", temperature=0)
        st.session_state.query_analyzer = QueryAnalyzer(llm=llm, logger=streamlit_logger)
    return st.session_state.query_analyzer

def show_query_analysis_sidebar(analysis):
    """Muestra el anÃ¡lisis de la consulta en la sidebar"""
    with st.sidebar:
        st.subheader("ğŸ” AnÃ¡lisis de Consulta")
        
        # Indicadores de relevancia
        col1, col2 = st.columns(2)
        with col1:
            if analysis['es_codigo_abierto']:
                st.success("âœ… CÃ³digo Abierto")
            else:
                st.error("âŒ CÃ³digo Abierto")
        
        with col2:
            if analysis['es_programacion']:
                st.success("âœ… ProgramaciÃ³n")
            else:
                st.error("âŒ ProgramaciÃ³n")
        
        # Confianza
        confidence = analysis['confianza']
        if confidence >= 0.7:
            st.success(f"ğŸ¯ Confianza: {confidence:.1%}")
        elif confidence >= 0.4:
            st.warning(f"ğŸ¤” Confianza: {confidence:.1%}")
        else:
            st.error(f"âŒ Confianza: {confidence:.1%}")
        
        # Repositorio detectado
        if analysis.get('repositorio'):
            st.info(f"ğŸ“ Repo detectado: `{analysis['repositorio']}`")
        
        # Razonamiento (si existe)
        if analysis.get('razonamiento'):
            with st.expander("ğŸ’­ Razonamiento"):
                st.write(analysis['razonamiento'])

def show_query_suggestions():
    """Muestra sugerencias de consultas vÃ¡lidas"""
    st.info("ğŸ’¡ **Prueba con estas consultas de ejemplo:**")
    
    suggestions = [
        "Â¿CÃ³mo instalar la librerÃ­a numpy?",
        "Â¿CuÃ¡les son las principales funcionalidades de React?",
        "Â¿QuÃ© dependencias necesita el proyecto tensorflow?",
        "Â¿CÃ³mo contribuir al repositorio de Django?",
        "Â¿CuÃ¡l es la licencia del proyecto pandas?",
        "Â¿Hay ejemplos de uso en el repositorio de scikit-learn?"
    ]
    
    cols = st.columns(2)
    for i, suggestion in enumerate(suggestions):
        col = cols[i % 2]
        with col:
            if st.button(suggestion, key=f"suggestion_{i}", use_container_width=True):
                st.session_state.user_query = suggestion
                st.rerun()

def handle_irrelevant_query(analysis):
    """Maneja consultas que no parecen relevantes"""
    st.warning("âš ï¸ **Esta consulta podrÃ­a no estar relacionada con el repositorio o programaciÃ³n.**")
    
    # Mostrar detalles del anÃ¡lisis
    with st.expander("Ver anÃ¡lisis detallado"):
        st.json(analysis)
    
    # Opciones para el usuario
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ Procesar de todas formas", type="secondary"):
            return True
    
    with col2:
        if st.button("âŒ Cancelar y reformular"):
            st.session_state.user_query = ""
            st.rerun()
    
    st.markdown("---")
    show_query_suggestions()
    return False

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="GitHub README Processor",
    page_icon="ğŸ™",
    layout="wide"
)

st.title("ğŸ™ Procesador de README de GitHub")

# Sidebar para configuraciÃ³n
with st.sidebar:
    st.header("âš™ï¸ ConfiguraciÃ³n")
    
    # Control de confianza mÃ­nima
    min_confidence = st.slider(
        "Confianza mÃ­nima para consultas",
        min_value=0.1,
        max_value=1.0,
        value=0.2,  # MÃ¡s permisivo para README especÃ­ficos
        step=0.1,
        help="Nivel mÃ­nimo de confianza para procesar automÃ¡ticamente la consulta"
    )
    
    # Modo debug
    debug_mode = st.checkbox("ğŸ” Mostrar anÃ¡lisis detallado")
    
    st.markdown("---")

# === SECCIÃ“N 1: PROCESAMIENTO DE README ===
st.header("ğŸ“‹ Paso 1: Procesar README")

col1, col2 = st.columns(2)
with col1:
    owner = st.text_input("Creador del repositorio (owner)", "", key="owner_input")
with col2:
    repo = st.text_input("Nombre del repositorio", "", key="repo_input")

if st.button("ğŸš€ Procesar README", type="primary"):
    if not owner or not repo:
        st.warning("Por favor, ingresa el creador y el nombre del repositorio.")
    else:
        # Descargar README
        gh_client = GitHubClient()
        readme = gh_client.fetch_readme(owner, repo)
        if not readme:
            st.error("No se pudo descargar el README.")
        else:
            st.success("âœ… README descargado correctamente.")
            
            # Guardar info del repo en session state
            st.session_state.current_repo = f"{owner}/{repo}"

            # Chunking
            with st.spinner("ğŸ“ Dividiendo README en chunks..."):
                chunker = Chunker(max_tokens=800)
                chunks = chunker.chunk(readme, overlap=100)
            st.success(f"ğŸ“„ README dividido en {len(chunks)} chunks.")

            # Embeddings
            with st.spinner("ğŸ§  Calculando embeddings..."):
                embedder = Embedder()
                embeddings = embedder.embed_chunks(chunks, normalize=True, return_with_text=True)
            st.success(f"âœ¨ Se calcularon {len(embeddings)} embeddings.")

            try:
                document = "README"
                with st.spinner("ğŸ’¾ Guardando embeddings en Pinecone..."):
                    vector_store = PineconeVectorStore(index_name="repo-text-embed-index")
                    vector_store.upsert_embeddings(embeddings, document, repo)
                st.success("ğŸ‰ Embeddings guardados en Pinecone correctamente.")
                
                # Marcar como procesado
                st.session_state.readme_processed = True
                
            except Exception as e:
                st.error(f"âŒ Error al guardar los embeddings en Pinecone: {e}")

# === SECCIÃ“N 2: CONSULTAS ===
st.header("ğŸ’¬ Consultar Repositorios")

# Info sobre repositorios disponibles
if st.session_state.get('readme_processed', False):
    st.info(f"ğŸ“ Ãšltimo README procesado: `{st.session_state.get('current_repo', 'Repositorio')}`")

st.markdown("ğŸ’¡ Puedes consultar cualquier repositorio que haya sido procesado previamente en la base de vectores.")

# Input de consulta
user_query = st.text_area(
    "âœï¸ **Escribe tu pregunta sobre cualquier repositorio:**",
    value=st.session_state.get('user_query', ''),
    height=100,
    placeholder="Ej: Â¿CÃ³mo instalar numpy? Â¿CuÃ¡les son las funcionalidades de tensorflow/tensorflow?",
    key="query_input"
)

# Botones de acciÃ³n
col1, col2, col3 = st.columns([2, 1, 1])

with col1:
    send_query_button = st.button("ğŸ” Enviar Consulta", type="primary")

with col2:
    if st.button("ğŸ“Š Solo Analizar"):
        if user_query.strip():
            analyzer = init_query_analyzer()
            with st.spinner("ğŸ” Analizando consulta..."):
                analysis = analyzer.analyze_query(user_query)
            show_query_analysis_sidebar(analysis)
        else:
            st.warning("Escribe una consulta primero.")

with col3:
    if st.button("ğŸ—‘ï¸ Limpiar"):
        st.session_state.user_query = ""
        st.rerun()

# Procesar consulta
if send_query_button:
    if not user_query.strip():
        st.warning("âš ï¸ Por favor, escribe una pregunta.")
    else:
        # Inicializar analizador
        analyzer = init_query_analyzer()
        
        # 1. Analizar la consulta
        with st.spinner("ğŸ” Analizando consulta..."):
            analysis = analyzer.analyze_query(user_query)
        
        # 2. Mostrar anÃ¡lisis en sidebar (si debug estÃ¡ activado)
        if debug_mode:
            show_query_analysis_sidebar(analysis)
        
        # 3. Verificar relevancia
        is_relevant = analyzer.is_relevant_query(user_query, min_confidence)
        
        if is_relevant:
            # 4. Procesar consulta relevante
            st.success("âœ… Consulta vÃ¡lida. Procesando...")
            
            with st.spinner("ğŸ¤– Buscando respuesta con el agente Orchestrator..."):
                try:
                    # Inicializar componentes
                    embedder = Embedder()
                    vector_store = PineconeVectorStore(index_name="repo-text-embed-index")
                    llm = Ollama(model="llama3.2:1b", temperature=0)
                    rag_agent = RAGAgent(embedder=embedder, vector_store=vector_store, llm=llm)
                    github_agent = GitHubAgent(github_tool=GitHubTool(), llm=llm)

                    orchestrator = OrchestratorAgent(
                        agents=[("RAGAgent", rag_agent)],
                        llm=llm,
                        logger=streamlit_logger
                    )
                    
                    # Ejecutar consulta
                    respuesta = orchestrator.run(user_query)
                    
                    # Mostrar respuesta
                    st.markdown("### ğŸ¯ Respuesta:")
                    st.write(respuesta)
                    
                    # Mostrar anÃ¡lisis en sidebar si estÃ¡ en modo debug
                    if debug_mode:
                        show_query_analysis_sidebar(analysis)
                    
                except Exception as e:
                    st.error(f"âŒ Error al procesar la consulta: {str(e)}")
        
        else:
            # 5. Manejar consulta irrelevante
            force_process = handle_irrelevant_query(analysis)
            
            if force_process:
                st.info("ğŸ”„ Procesando en modo experimental...")
                
                with st.spinner("ğŸ¤– Procesando consulta..."):
                    try:
                        embedder = Embedder()
                        vector_store = PineconeVectorStore(index_name="repo-text-embed-index")
                        llm = Ollama(model="llama3.2:1b", temperature=0)
                        rag_agent = RAGAgent(embedder=embedder, vector_store=vector_store, llm=llm)

                        orchestrator = OrchestratorAgent(
                            agents=[("RAGAgent", rag_agent)],
                            llm=llm,
                            logger=streamlit_logger
                        )
                        
                        respuesta = orchestrator.run(user_query)
                        
                        st.warning("âš ï¸ **Resultado experimental:**")
                        st.write(respuesta)
                        
                    except Exception as e:
                        st.error(f"âŒ Error al procesar la consulta: {str(e)}")

# Mostrar sugerencias si no hay consulta
if not user_query.strip():
    st.markdown("---")
    show_query_suggestions()

# Footer con informaciÃ³n
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        ğŸ™ GitHub README Processor | Consulta repositorios procesados previamente | Powered by RAG + LLM
    </div>
    """, 
    unsafe_allow_html=True
)